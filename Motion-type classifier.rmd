---
title: "Motion-type classifier"
author: "Uran Chu"
date: "March 1, 2016"
output: html_document
---

This exercises import a fixed training and testing set of data to classify 5 different types of motions according to 54 covariates.

We will use library caret to do the data mining.

```{r libraries loader}
library(caret)
```

We first save the training set data, called pml-training.csv, and the test set data, called pml-testing.csv, to our home directory C://Rtools.  We then opened both in Excel, and got rid of all the columns with empty cells and NA's.  We disceover that there is no missing data to impute because each variable has either all missing data in it, or all data.  We simply get rid of all the variables with either no data or NA listed under the column for both the training and testing sets.  They are the same variables and no further adjumstments are needed.

First, we import the training and testing data sets into our home directory (mine is C://Rtools on my windows-base-operating-system-computer)  The training data set has 19,622 observations and 60 variables, while the testing data set hass 20 test cases and 60 variables.


```{r dataImport}
training <- read.csv("C://Rtools//pml-traininga.csv")
testing <- read.csv("C://Rtools//pml-testinga.csv")
```

We then check out what variables are in the training set of data.

```{r variables}
str(training)
```

We discover that columns 1 to 5 are date-stamp and index type variables that are not useful as predictors, and the "classe" variable is the response variable with five possible classes, A, B, C, D, and E, that are at the 60th column.

We check out whether there are near-zero variance variables to exclude; predictor variables with almost all the same value are not very good predictors, and we look to screen these variables out before training.  We looked at predictor variables 6 to 59 because first 5 columns are time-stamps and index identifiers, while the 60th variable is the response.

```{r variable-filter}
nzv(training[, 6:59])
```

As the routine returns 1, the 6th column variable has near zero variance.  str function says it is a variable called new_window; it is a factor variable with two variables.  I decided to look further into it:

```{r new_window examiner}
table(training$new_window)
```

I understand that with such lop-sided proportion between the yeses and no's, we might consider leaving the variable out of the predictor set.  But 406 yeses is still substantial, and I decided to leave the variable in.

It is time to train our model.  As random forests or boosting are two algorithms that consistent win prediction contests, our first choice to train our classification model is the random forests. This will take a little time but it is well worth the time. 

```{r Random-Forest-classifier trainer}
attach(training)
ModFitRF <- train(classe~., method = "rf", data = training[,6:59])
detach(training)
```

After waiting a few hours, the model returns and we can use it for prediction on our test set:
     
```{r Random-Forest-classifier tester (validation)}
predict(ModFitRF, testing)
```

The prediction across the 20 test cases is perfect, according to the Quiz 2 module during 4th week.  I received a 100% on prediction accuracy from that quiz.

Random forests, though it takes a long time to train, seems to be a great predictor.  
